{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## Table of Contents\n\n1. [Import Libraries](#1)<br>\n2. [Inception Model](#2)<br>\n3. [ResNet Model](#3)<br>","metadata":{}},{"cell_type":"markdown","source":"# 游릭Import Libraries <a id =\"1\" ><a>","metadata":{}},{"cell_type":"code","source":"import cv2\nimport tensorflow as tf\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport time","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import PIL\nfrom tensorflow.keras.layers import Dense,Flatten,Dropout\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.optimizers import Adam ,SGD\nfrom sklearn.metrics import mean_squared_error as MSE_SKL\nfrom sklearn.metrics import mean_absolute_error as MAE_SKL\nfrom tensorflow.keras.metrics import mean_absolute_error as MAE_TF\nfrom tensorflow.keras.regularizers import L2","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(plt.style.available)\nplt.style.use('ggplot')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 游릭 Create Training Data  ","metadata":{}},{"cell_type":"code","source":"train_inputImg = pd.read_csv('../input/cephalometric-landmarks/train_senior.csv', delimiter=',')\n\ntrain_images = []\ntrain_images_rgb_blured = []\n\ntrain_images_hsv = []\ntrain_images_hsv_blured  = []\n\ntrain_coords=[]\n\n\n\nfor row in train_inputImg.values:\n    image_object = list(row)\n    coords = image_object[1:]\n    train_x_1_coord = []\n    train_y_1_coord = []\n    for i in range(0,len(coords)-1,2):\n        train_x_1_coord.append((coords[i])/10)\n        train_x_1_coord.append((coords[i+1])/10)\n    train_coords.append(np.array(train_x_1_coord))\n    \n    gray_image = cv2.imread('../input/cephalometric-landmarks/cepha400/cepha400/' + image_object[0],cv2.IMREAD_GRAYSCALE ) \n    #print(gray_image.shape)\n    gray_resized_image = cv2.resize(gray_image,(193,240))\n    gray_resized_image = cv2.normalize(gray_resized_image, None, 0, 1.0,cv2.NORM_MINMAX, dtype=cv2.CV_32F)\n    #print(f\"max = {np.max(gray_resized_image,axis=0)} , min = {np.min(gray_resized_image,axis=0)} \")\n    rgb_resized_image = cv2.cvtColor(gray_resized_image,cv2.COLOR_GRAY2RGB)\n    blured_rgb_resized_image = cv2.blur(rgb_resized_image,(3,3))\n    \n    hsv_resized_image = cv2.cvtColor(rgb_resized_image, cv2.COLOR_BGR2HSV)\n    blured_hsv_resized_image = cv2.blur(hsv_resized_image ,(3,3))\n    \n    train_images.append(rgb_resized_image)\n    train_images_rgb_blured.append(blured_rgb_resized_image)\n    \n    train_images_hsv.append(hsv_resized_image)\n    train_images_hsv_blured.append(blured_hsv_resized_image)\n    ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"blur = cv2.blur(train_images[0],(3,3))\nplt.imshow(blur)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"Type of train_images\", type(train_images))\nprint(\"Shape of Training Images\",(np.array(train_images).shape),\"\\n\")\n\nprint(\"Type of train_images\", type(train_images_hsv))\nprint(\"Shape of Training Images\",(np.array(train_images_hsv).shape),\"\\n\")\n\nprint(\"Type of train_coords\", type(train_coords))\nprint(\"Shape of train_coords\",(np.array(train_coords).shape))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 游릭 Create Validation Data  ","metadata":{}},{"cell_type":"code","source":"val_inputImg = pd.read_csv('../input/cephalometric-landmarks/test1_senior.csv', delimiter=',')\nval_images = []\ntrain_images_rgb_blured = []\ntrain_images_hsv_blured  = []\n\n\nval_images_hsv = []\nval_images_rgb_blured = []\nval_images_hsv_blured  = []\n\nval_coords = []\n\ncount = 1\n\nfor row in val_inputImg.values:\n    image_object = list(row)\n    coords = image_object[1:]\n    train_x_1_coord = []\n    train_y_1_coord = []\n    val_x_1_coord = []\n    val_y_1_coord = []\n    \n    gray_image = cv2.imread('../input/cephalometric-landmarks/cepha400/cepha400/' + image_object[0],cv2.IMREAD_GRAYSCALE ) \n    gray_resized_image = cv2.resize(gray_image,(193,240))\n    gray_resized_image = cv2.normalize(gray_resized_image, None, 0, 1.0,cv2.NORM_MINMAX, dtype=cv2.CV_32F)\n    rgb_resized_image = cv2.cvtColor(gray_resized_image,cv2.COLOR_GRAY2RGB)\n    blured_rgb_resized_image = cv2.blur(rgb_resized_image,(3,3))\n    \n    hsv_resized_image = cv2.cvtColor(rgb_resized_image, cv2.COLOR_BGR2HSV)\n    blured_hsv_resized_image = cv2.blur(hsv_resized_image ,(3,3))\n    \n    if count <= 100:\n            train_images.append(rgb_resized_image)\n            train_images_hsv.append(hsv_resized_image)\n            train_images_rgb_blured.append(blured_rgb_resized_image)\n            train_images_hsv_blured.append(blured_hsv_resized_image)\n\n    else:\n            val_images.append(rgb_resized_image)\n            val_images_hsv.append(hsv_resized_image)\n            val_images_rgb_blured.append(blured_rgb_resized_image)\n            val_images_hsv_blured.append(blured_hsv_resized_image)\n            \n    for i in range(0,len(coords)-1,2):\n        \n        if count <= 100:\n            train_x_1_coord.append((coords[i])/10)\n            train_x_1_coord.append((coords[i+1])/10)\n        \n        else:\n            val_x_1_coord.append((coords[i])/10)\n            val_x_1_coord.append((coords[i+1])/10)\n    if count<=100:\n        train_coords.append(np.array(train_x_1_coord))\n    else:\n        val_coords.append(np.array(val_x_1_coord))\n\n    \n    count += 1\n    ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"Type of val_images\", type(val_images))\nprint(\"Shape of val_images \",(np.array(val_images).shape),\"\\n\")\n\nprint(\"Type of val_images\", type(val_images_hsv))\nprint(\"Shape of val_images \",(np.array(val_images_hsv).shape),\"\\n\")\n\nprint(\"Type of val_coords\", type(val_coords))\nprint(\"Shape of val_coords\",(np.array(val_coords).shape))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 游릭 Import Testing Data","metadata":{}},{"cell_type":"code","source":"test_inputImg = pd.read_csv('../input/cephalometric-landmarks/test2_senior.csv', delimiter=',')\ntest_images = []\ntest_images_rgb_blured = []\n\ntest_images_hsv = []\ntest_images_hsv_blured = []\n\ntest_coords = []\n\n\n\nfor row in test_inputImg.values:\n    image_object = list(row)\n    coords = image_object[1:]\n    test_x_1_coord = []\n    for i in range(0,len(coords)-1,2):\n        test_x_1_coord.append((coords[i])/10)\n        test_x_1_coord.append((coords[i+1])/10)\n    test_coords.append(np.array(test_x_1_coord))\n    gray_image = cv2.imread('../input/cephalometric-landmarks/cepha400/cepha400/' + image_object[0],cv2.IMREAD_GRAYSCALE ) \n    gray_resized_image = cv2.resize(gray_image,(193,240))\n    gray_resized_image = cv2.normalize(gray_resized_image, None, 0, 1.0,cv2.NORM_MINMAX, dtype=cv2.CV_32F)\n    rgb_resized_image = cv2.cvtColor(gray_resized_image,cv2.COLOR_GRAY2RGB)\n    blured_rgb_resized_image = cv2.blur(rgb_resized_image,(3,3))\n    \n    hsv_resized_image = cv2.cvtColor(rgb_resized_image, cv2.COLOR_BGR2HSV)\n    blured_hsv_resized_image = cv2.blur(hsv_resized_image ,(3,3))\n\n    \n    test_images.append(rgb_resized_image)\n    test_images_rgb_blured.append(blured_rgb_resized_image)\n\n    test_images_hsv.append(hsv_resized_image)\n    test_images_hsv_blured.append(blured_hsv_resized_image)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"Type of test_images\", type(test_images))\nprint(\"Shape of test_images \",(np.array(test_images).shape),\"\\n\")\n\nprint(\"Type of test_images\", type(test_images_hsv))\nprint(\"Shape of test_images \",(np.array(test_images_hsv).shape),\"\\n\")\n\nprint(\"Type of test_coords\", type(test_coords))\nprint(\"Shape of test_coords\",(np.array(test_coords).shape))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Final Sets Shape ","metadata":{}},{"cell_type":"code","source":"print(\"********* Training Set *********\")\nprint(\"Shape of Training Images\",(np.array(train_images).shape),\"\\n\")\nprint(\"Shape of Training Images\",(np.array(train_images_hsv).shape),\"\\n\")\nprint(\"Shape of train_coords\",(np.array(train_coords).shape),\"\\n\")\n\nprint(\"********* Validation Set *********\")\nprint(\"Shape of val_images \",(np.array(val_images).shape),\"\\n\")\nprint(\"Shape of test_images \",(np.array(val_images_hsv).shape),\"\\n\")\nprint(\"Shape of val_coords\",(np.array(val_coords).shape),\"\\n\")\n\nprint(\"********* Test Set *********\")\nprint(\"Shape of test_images \",(np.array(test_images).shape),\"\\n\")\nprint(\"Shape of test_images \",(np.array(test_images_hsv).shape),\"\\n\")\nprint(\"Shape of test_coords\",(np.array(test_coords).shape))\n\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 游릭 Stack Training Data","metadata":{}},{"cell_type":"code","source":"train_images_stacked = np.stack(train_images, axis=0)\ntrain_images_rgb_blured_stacked = np.stack(train_images_rgb_blured, axis=0)\n\n\ntrain_images_hsv_stacked = np.stack(train_images_hsv, axis=0)\ntrain_images_hsv_blured_stacked = np.stack(train_images_hsv_blured, axis=0)\n\n\n\ntrain_labels = np.array(train_coords)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"img = cv2.circle(train_images_stacked[0], (int(train_labels[0][0]),int(train_labels[0][1])), 2, (255,0,0),-1)\nplt.imshow(img)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"img_ = cv2.circle(train_images_stacked[0], (800,1080), 25, (255,0,0),-1)\nplt.imshow(img_)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 游릭 Stack Validation Data","metadata":{}},{"cell_type":"code","source":"val_images_stacked= np.stack(val_images, axis=0)\nval_images_rgb_blured_stacked= np.stack(val_images_rgb_blured, axis=0)\n\n\nval_images_hsv_stacked= np.stack(val_images_hsv, axis=0)\nval_images_hsv_blured_stacked= np.stack(val_images_hsv_blured, axis=0)\n\nval_labels = np.array(val_coords)\n\nval_data = (val_images_stacked,val_labels)\nval_data_rgb_blured = (val_images_rgb_blured_stacked,val_labels)                                        \n\nval_data_hsv = (val_images_hsv_stacked,val_labels)\nval_data_hsv_blured = (val_images_hsv_blured_stacked,val_labels)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"\n## 游릭 Stack Test Data","metadata":{}},{"cell_type":"code","source":"test_images_stacked= np.stack(test_images, axis=0)\ntest_images_rgb_blured_stacked= np.stack(test_images_rgb_blured, axis=0)\n\ntest_images_hsv_stacked= np.stack(test_images_hsv, axis=0)\ntest_images_hsv_blured_stacked= np.stack(test_images_hsv_blured, axis=0)\n\n\ntest_labels = np.array(test_coords)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Final Stacked Shape","metadata":{}},{"cell_type":"code","source":"print(\"********* Stacked Training Set *********\")\nprint(\"Type of train_images_stacked\",(type(train_images_stacked)))\nprint(\"Shape of train_images_stacked\",((train_images_stacked).shape))\nprint(\"Shape of train_images_stacked\",((train_images_rgb_blured_stacked).shape))\nprint(\"Shape of train_images_stacked\",((train_images_hsv_blured_stacked).shape))\nprint(\"Type of train_labels\",(type(train_labels)))\nprint(\"Shape of train_labels\",((train_labels).shape),\"\\n\")\n\nprint(\"********* Stacked Validation Set *********\")\nprint(\"Shape of val_images_stacked \",((val_images_stacked).shape))\nprint(\"Shape of val_labels\",((val_labels).shape))\nprint(\"Val_datet => (val_labels,val_labels)\")\nprint(\"Type of val_data\",(type(val_data)),\"\\n\")\n\nprint(\"********* Stacked Test Set *********\")\nprint(\"Type of test_labels\",(type(test_labels)))\nprint(\"Shape of test_images_stacked \",((test_images_stacked).shape))\nprint(\"Type of test_labels\",(type(test_labels)))\nprint(\"Shape of test_labels\",((test_labels).shape))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Radial Error Loss Metric","metadata":{}},{"cell_type":"code","source":"# def mean_radial_error(X_Y_True,X_Y_Predicred):\n#     delta_x_2 =  np.power( ( np.subtract(X_Y_True[:,0,:] , X_Y_Predicred[:,0,:]) ) , 2) #(2,4)\n#     delta_y_2 =  np.power( ( np.subtract(X_Y_True[:,1,:] , X_Y_Predicred[:,1,:]) ) , 2) #(2,4)\n\n#     radial_error_lm_ex = np.sqrt(np.add(delta_x_2,delta_y_2)) #(2,4)\n\n#     radial_error_ex = np.sum(radial_error_lm_ex, axis = 1) #(2,)\n\n#     radial_error =  np.sum(radial_error_ex, axis = 0)\n\n#     mean_radial_error = radial_error / len(radial_error_ex)\n\n    \n#     return mean_radial_error\n    ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Mean Radial Error For each Landmark","metadata":{}},{"cell_type":"code","source":"# def mean_radial_error_landmark(x_y_true,x_y_pred):\n#     delta_x_2 =  np.power( ( np.subtract(x_y_true[:,0,:] , x_y_pred[:,0,:]) ) , 2) #(2,4)\n#     delta_y_2 =  np.power( ( np.subtract(x_y_true[:,1,:] , x_y_pred[:,1,:]) ) , 2) #(2,4)\n\n#     radial_error_lm_ex = np.sqrt(np.add(delta_x_2,delta_y_2)) #(2,4)\n\n# #     print(radial_error_lm_ex)\n\n#     radial_error_lm = np.sum(radial_error_lm_ex, axis = 0,keepdims=True) #(1,4)\n# #     print(radial_error_lm)\n\n#     mean_radial_error_lm = radial_error_lm / x_y_true.shape[0]\n#     print(x_y_true.shape[0])\n    \n#     return mean_radial_error_lm","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def mean_radial_error_landmark(x_true,y_true,x_pred,y_pred):\n    delta_x_2 =  np.power( ( np.subtract(x_true , x_pred) ) , 2) #(2,4)\n    delta_y_2 =  np.power( ( np.subtract(y_true, y_pred ) ) , 2) #(2,4)\n\n    radial_error_lm_ex = np.sqrt(np.add(delta_x_2,delta_y_2)) #(2,4)\n\n#     print(radial_error_lm_ex)\n\n    radial_error_lm = np.sum(radial_error_lm_ex, axis = 0,keepdims=True) #(1,4)\n#     print(radial_error_lm)\n\n    mean_radial_error_lm = radial_error_lm / x_true.shape[0]\n    print(x_true.shape[0])\n    \n    return radial_error_lm_ex,mean_radial_error_lm","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 游댯 Create InceptionResNetV2 Model  <a id=\"2\"></a>","metadata":{}},{"cell_type":"code","source":"from keras.models import Model\n\npretrained_model= tf.keras.applications.InceptionResNetV2(include_top=False,\n                   input_shape=(240,193,3),\n                                                          \n                   weights='imagenet')\nfor layer in pretrained_model.layers:\n        layer.trainable=False\n# add a global spatial average pooling layer\nx = pretrained_model.output\nx =  tf.keras.layers.Flatten()(x)\n# let's add a fully-connected layer\n#x = Dense(1024, activation='relu')(x)\n#x =Dropout(0.3)(x)\nx = Dense(512, activation='relu')(x)\nx =Dropout(0.3)(x)\nx = Dense(256, activation='relu')(x)\nx =Dropout(0.3)(x)\n# and a linear output layer\nprediction = Dense(38, activation='linear')(x)\n# this is the model we will train\nInceptionResNetV2 = Model(inputs=pretrained_model.input, outputs=prediction)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 游댯 Compile Model","metadata":{}},{"cell_type":"code","source":"reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss',factor=0.1,\n                                                patience=5,\n                                                min_delta=0.001)\n\nInceptionResNetV2.compile(optimizer=Adam(learning_rate=0.4),loss='mae',metrics=['mae'])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 游댯 Fit Model","metadata":{}},{"cell_type":"code","source":"start_time = time.time()\nhistory = InceptionResNetV2.fit(train_images_hsv_stacked,train_labels, validation_data = val_data_hsv, epochs=400)\nend_time = time.time()\nprint(\"Training_time:\",end_time-start_time)","metadata":{"scrolled":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.plot(history.history['loss'], label = \"Training Loss\")\nplt.plot(history.history['val_loss'], label = \"Val Loss\")\nplt.legend()\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 游댯 Make Predictions\n","metadata":{}},{"cell_type":"code","source":"start_time = time.time()\n\nprediction_IncepRes=InceptionResNetV2.predict(test_images_stacked)\n\nend_time =  time.time()\n\nprint(\"prediction_time:\",end_time-start_time)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"MAE_SKL(test_labels, prediction_IncepRes)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"x_coored_ind = np.arange(start=0, stop=38, step=2)\ny_coored_ind = np.arange(start=1, stop=39, step=2)\n\nx_true = test_labels[:,x_coored_ind]\ny_true = test_labels[:,y_coored_ind]\n\nx_pred_incep = prediction_IncepRes[:,x_coored_ind]\ny_pred_incep = prediction_IncepRes[:,y_coored_ind]\n\nmre_each_lm_incep=(mean_radial_error_landmark(x_true,y_true,x_pred_incep,y_pred_incep)).reshape(19)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"delta_x_incep = ( np.subtract(x_true , x_pred_incep) )\ndelta_x_lm_incep = np.sum(delta_x_incep, axis = 0,keepdims=True)/100\ndifference_x_incep=(delta_x_lm_incep).reshape(19)\n\ndelta_y_incep = ( np.subtract(y_true , y_pred_incep) )\ndelta_y_lm_incep = np.sum(delta_y_incep, axis = 0,keepdims=True)/100\ndifference_y_incep =(delta_y_lm_incep).reshape(19)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"landmark = np.array(np.arange(1,20),dtype=int)\nimport pandas as pd\n\nresults_incep = pd.DataFrame({\"landmark\":landmark,\n                        \"Mean Radial Error\":mre_each_lm_incep,\n                        \"X_true - X_pred\":difference_x_incep,\n                        \"y_true - y_pred\":difference_y_incep})\nresults_incep.set_index(['landmark'])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for i in range(len(test_labels)):\n    print(f'mae of image {i}  = {mean_absolute_error(test_labels[i], prediction_IncepRes[i])}')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"img_number = 56\nimg = np.copy(test_images_stacked[img_number])\nfor i in range(0,len(test_labels[img_number])-1,2):\n    img = cv2.circle(img, (int(test_labels[img_number][i]),int(test_labels[img_number][i+1])), 2, (255,0,0),-1)\n    img = cv2.circle(img, (int(prediction_IncepRes[img_number][i]),int(prediction_IncepRes[img_number][i+1])), 2, (0,255,0),-1)\nplt.imshow(img)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"img_number = 55\nimg = np.copy(test_images_stacked[img_number])\nfor i in range(0,len(test_labels[img_number])-1,2):\n    img = cv2.circle(img, (int(test_labels[img_number][i]),int(test_labels[img_number][i+1])), 2, (255,0,0),-1)\n    img = cv2.circle(img, (int(prediction_IncepRes[img_number][i]),int(prediction_IncepRes[img_number][i+1])), 2, (0,255,0),-1)\nplt.imshow(img)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"img_number = 68\nimg = np.copy(test_images_stacked[img_number])\nfor i in range(0,len(test_labels[4])-1,2):\n    img = cv2.circle(img, (int(test_labels[img_number][i]),int(test_labels[img_number][i+1])), 2, (255,0,0),-1)\n    img = cv2.circle(img, (int(prediction_IncepRes[img_number][i]),int(prediction_IncepRes[img_number][i+1])), 2, (0,255,0),-1)\nplt.imshow(img)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"InceptionResNetV2.save('incep_adabtiveLR.h5')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from IPython.display import FileLink\nFileLink(\"./incep_adabtiveLR.h5\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 游리 K-fold Cross validation<a id=\"3\"></a>","metadata":{}},{"cell_type":"code","source":"inputs = np.concatenate((train_images_stacked, val_images_stacked), axis=0)\ntargets = np.concatenate((train_labels, val_labels), axis=0)\nprint(inputs.shape)\nprint(targets.shape)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import KFold\nfrom keras.models import Model\nimport tensorflow_addons as tfa\n# Merge inputs and targets\ninputs = np.concatenate((train_images_stacked, val_images_stacked), axis=0)\ntargets = np.concatenate((train_labels, val_labels), axis=0)\n# Define the K-fold Cross Validator\nkfold = KFold(n_splits=5, shuffle=True)\n# K-fold Cross Validation model evaluation\nfold_no = 1\n# Define per-fold score containers\nacc_per_fold = []\nloss_per_fold = []\nfor train, val in kfold.split(inputs, targets):\n  # Generate a print\n    print('------------------------------------------------------------------------')\n    print(f'Training for fold {fold_no} ...')\n\n  # Fit data to model\n#   history = model.fit(inputs[train], targets[train],\n#               batch_size=batch_size,\n#               epochs=no_epochs,\n#               verbose=verbosity)\n\n\n    pretrained_model= tf.keras.applications.InceptionResNetV2(include_top=False,\n                       input_shape=(240,193,3),\n                        pooling='avg',\n                       weights='imagenet')\n    for layer in pretrained_model.layers:\n            layer.trainable=False\n    # add a global spatial average pooling layer\n    x = pretrained_model.output\n    x =  tf.keras.layers.Flatten()(x)\n    x =Dropout(0.25)(x)\n    x = Dense(1024, activation='relu',kernel_initializer = 'he_normal')(x)\n#     x =Dropout(0.25)(x)\n    x = Dense(512, activation='relu',kernel_initializer = 'he_normal')(x)\n#     x =Dropout(0.25)(x)\n    x = Dense(256, activation='relu',kernel_initializer = 'he_normal')(x)\n#     x =Dropout(0.25)(x)\n    x = Dense(128, activation='relu',kernel_initializer = 'he_normal')(x)\n    x =Dropout(0.25)(x)\n    # and a linear output layer\n    prediction = Dense(38, activation='linear')(x)\n    # this is the model we will train\n    InceptionResNetV2 = Model(inputs=pretrained_model.input, outputs=prediction)\n    clr = tfa.optimizers.CyclicalLearningRate(initial_learning_rate=10e-4,\n    maximal_learning_rate=0.1,\n    scale_fn=lambda x: 1/(2.**(x-1)),\n    step_size=2 * 32)\n    \n    InceptionResNetV2.compile(optimizer=Adam(clr),loss='mae',metrics=['mae'])\n    history = InceptionResNetV2.fit(inputs[train], targets[train], validation_data = (inputs[val], targets[val]), batch_size = 32,epochs=400) \n\n  # Generate generalization metrics\n    scores = InceptionResNetV2.evaluate(test_images_stacked, test_labels, verbose=0)\n    print(f'Score for fold {fold_no}: {InceptionResNetV2.metrics_names[0]} of {scores[0]}; {InceptionResNetV2.metrics_names[1]} of {scores[1]*100}%')\n    acc_per_fold.append(scores[1] * 100)\n    loss_per_fold.append(scores[0])\n    InceptionResNetV2.save(f\"InceptionV2_fold{fold_no}\")\n\n  # Increase fold number\n    fold_no = fold_no + 1\n\n# == Provide average scores ==\nprint('------------------------------------------------------------------------')\nprint('Score per fold')\nfor i in range(0, len(acc_per_fold)):\n  print('------------------------------------------------------------------------')\n  print(f'> Fold {i+1} - Loss: {loss_per_fold[i]} - Accuracy: {acc_per_fold[i]}%')\nprint('------------------------------------------------------------------------')\nprint('Average scores for all folds:')\nprint(f'> Accuracy: {np.mean(acc_per_fold)} (+- {np.std(acc_per_fold)})')\nprint(f'> Loss: {np.mean(loss_per_fold)}')\nprint('------------------------------------------------------------------------')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import KFold\nfrom keras.models import Model\nimport tensorflow_addons as tfa\n# Merge inputs and targets\ninputs = np.concatenate((train_images_stacked, val_images_stacked), axis=0)\ntargets = np.concatenate((train_labels, val_labels), axis=0)\n# Define the K-fold Cross Validator\nkfold = KFold(n_splits=5, shuffle=True)\n# K-fold Cross Validation model evaluation\nfold_no = 1\n# Define per-fold score containers\nacc_per_fold = []\nloss_per_fold = []\nfor train, val in kfold.split(inputs, targets):\n  # Generate a print\n    print('------------------------------------------------------------------------')\n    print(f'Training for fold {fold_no} ...')\n\n  # Fit data to model\n#   history = model.fit(inputs[train], targets[train],\n#               batch_size=batch_size,\n#               epochs=no_epochs,\n#               verbose=verbosity)\n\n\n\n    pretrained_model2= tf.keras.applications.ResNet50(include_top=False,\n                       input_shape=(240,193,3),\n                        pooling='avg',\n                       weights='imagenet')\n\n    for layer in pretrained_model2.layers:\n            layer.trainable=False\n    # add a global spatial average pooling layer\n    x = pretrained_model2.output\n    x =  tf.keras.layers.Flatten()(x)\n    # let's add a fully-connected layer\n    x =Dropout(0.25)(x)\n    x = Dense(1024, activation='relu',kernel_initializer = 'he_normal')(x)\n#     x =Dropout(0.25)(x)\n    x = Dense(512, activation='relu',kernel_initializer = 'he_normal')(x)\n#     x =Dropout(0.25)(x)\n    x = Dense(256, activation='relu',kernel_initializer = 'he_normal')(x)\n#     x =Dropout(0.25)(x)\n    x = Dense(128, activation='relu',kernel_initializer = 'he_normal')(x)\n    x =Dropout(0.25)(x)\n    # and a linear output layer\n    prediction = Dense(38, activation='linear')(x)\n    # this is the model we will train\n    resnet50_model = Model(inputs=pretrained_model2.input, outputs=prediction)\n    clr = tfa.optimizers.CyclicalLearningRate(initial_learning_rate=10e-4,\n    maximal_learning_rate=0.1,\n    scale_fn=lambda x: 1/(2.**(x-1)),\n    step_size=2 * 32)\n    \n    resnet50_model.compile(optimizer=Adam(clr),loss='mae',metrics=['mae'])\n    history = resnet50_model.fit(inputs[train], targets[train], validation_data = (inputs[val], targets[val]), batch_size = 32,epochs=400) \n\n  # Generate generalization metrics\n    scores = resnet50_model.evaluate(test_images_stacked, test_labels, verbose=0)\n    print(f'Score for fold {fold_no}: {resnet50_model.metrics_names[0]} of {scores[0]}; {resnet50_model.metrics_names[1]} of {scores[1]}%')\n    acc_per_fold.append(scores[1] )\n    loss_per_fold.append(scores[0])\n    resnet50_model.save(f\"resnet50_model_fold{fold_no}.h5\")\n\n  # Increase fold number\n    fold_no = fold_no + 1\n\n# == Provide average scores ==\nprint('------------------------------------------------------------------------')\nprint('Score per fold')\nfor i in range(0, len(acc_per_fold)):\n  print('------------------------------------------------------------------------')\n  print(f'> Fold {i+1} - Loss: {loss_per_fold[i]} - Accuracy: {acc_per_fold[i]}%')\nprint('------------------------------------------------------------------------')\nprint('Average scores for all folds:')\nprint(f'> Accuracy: {np.mean(acc_per_fold)} (+- {np.std(acc_per_fold)})')\nprint(f'> Loss: {np.mean(loss_per_fold)}')\nprint('------------------------------------------------------------------------')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 游리 Create ResNet50 model <a id=\"3\"></a>","metadata":{}},{"cell_type":"code","source":"from keras.models import Model\nimport tensorflow_addons as tfa\npretrained_model2= tf.keras.applications.ResNet50(include_top=False,\n                   input_shape=(240,193,3),                    \n                   weights='imagenet')\n\nfor layer_no , layer in zip(range(1,len(pretrained_model2.layers)+1),pretrained_model2.layers): #176 Layers\n#     if layer_no > 172:\n#         layer.trainable=True\n#     else:\n        layer.trainable=False\n    \n#     print(layer_no)\nx = pretrained_model2.output\nx =  tf.keras.layers.Flatten()(x)\n\ninitializer = tf.keras.initializers.RandomUniform(minval=0., maxval=1.) #kernel_initializer=initializer\n\n\n# x = Dense(2048, activation='relu', kernel_initializer = 'he_normal')(x)\nx = Dense(1024, activation='relu', kernel_initializer = 'he_normal')(x)\n# # x =Dropout(0.25)(x)\n# x = Dense(512, activation='relu', kernel_initializer = 'he_normal')(x)\n# # x =Dropout(0.25)(x)\n# x = Dense(256, activation='relu', kernel_initializer = 'he_normal')(x)\n# # x =Dropout(0.25)(x)\n# x = Dense(128, activation='relu', kernel_initializer = 'he_normal')(x)\n# # x =Dropout(0.25)(x)\n\n#x = Dense(512, activation='relu',kernel_initializer=initializer)(x)\n\n# x = Dense(128, activation='relu')(x)\n\nprediction = Dense(38, activation='linear')(x)\n\nresnet50_model = Model(inputs=pretrained_model2.input, outputs=prediction)\n","metadata":{"scrolled":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"resnet50_model.summary()","metadata":{"scrolled":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 游리 Adabtive Learning Rate","metadata":{}},{"cell_type":"code","source":"!pip install -q -U tensorflow_addons","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import tensorflow_addons as tfa\nclr = tfa.optimizers.CyclicalLearningRate(initial_learning_rate=10e-2,\n    maximal_learning_rate=0.5,\n    scale_fn=lambda x: 1/(2.**(x-1)),\n    step_size=2 * 64\n)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss',factor=0.1,\n                                                patience=5,\n                                                min_delta=0.002)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"checkpoint_filepath = '/resnet/checkpoint'\n\nresnet_model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n    filepath=checkpoint_filepath,\n    save_weights_only=True,\n    monitor='val_loss',\n    mode='min',\n    save_best_only=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 游리 Compile Model","metadata":{}},{"cell_type":"code","source":"resnet50_model.compile(optimizer=Adam(learning_rate = 0.1),loss='mae',metrics=['mae'])\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 游리 Fit Model","metadata":{}},{"cell_type":"code","source":"start_time = time.time()\n\nhistory = resnet50_model.fit(train_images_stacked,train_labels, validation_data = val_data, epochs=400,batch_size =64,)\n\nend_time =  time.time()\n\nprint(\"Trining_time: \",end_time-start_time )","metadata":{"scrolled":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.plot(history.history['loss'], label = \"Training Loss\")\nplt.plot(history.history['val_loss'], label = \"Val Loss\")\nplt.legend()\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"step = np.arange(0, 100 * 64)\n# lr = clr(step)\nplt.plot(step, clr)\nplt.xlabel(\"Steps\")\nplt.ylabel(\"Learning Rate\")\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 游리 Make Predictions","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"start_time = time.time()\n\nprediction_ResNet50=resnet50_model.predict(test_images_stacked)\n\nend_time =  time.time()\n\nprint(\"prediction_time: \",end_time-start_time )","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"MSE: \",MSE_SKL(test_labels, prediction_ResNet50))\nprint(\"MAE: \",MAE_SKL(test_labels, prediction_ResNet50))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Mean Radial Error for each LandMark along Test Set","metadata":{}},{"cell_type":"code","source":"x_coored_ind = np.arange(start=0, stop=38, step=2)\ny_coored_ind = np.arange(start=1, stop=39, step=2)\n\nx_true = test_labels[:,x_coored_ind]\ny_true = test_labels[:,y_coored_ind]\n\nx_pred = prediction_ResNet50[:,x_coored_ind]\ny_pred = prediction_ResNet50[:,y_coored_ind]\n\nradial_error_lm_ex_resnet , mre_each_lm_resnet = (mean_radial_error_landmark(x_true,y_true,x_pred,y_pred))\nmre_each_lm_resnet = mre_each_lm_resnet.reshape(19)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Radial Error for each LandMark across 100 test image","metadata":{}},{"cell_type":"code","source":"import seaborn as sns\nplt.figure(figsize=(15,8))\nsns.boxplot(data = radial_error_lm_ex_resnet[:,:])\nplt.xlabel(\"LandMarks\")\nplt.ylabel(\"Error mm\")\nplt.title(\"Radial Error for each LandMark across 100 test image\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"delta_x = ( np.subtract(x_true , x_pred) )\ndelta_x_lm = np.sum(delta_x, axis = 0,keepdims=True)/100\ndifference_x=(delta_x_lm).reshape(19)\n\ndelta_y = ( np.subtract(y_true , y_pred) )\ndelta_y_lm = np.sum(delta_y, axis = 0,keepdims=True)/100\ndifference_y =(delta_y_lm).reshape(19)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\nlandmark = np.array(np.arange(1,20),dtype=int)\nresults = pd.DataFrame({\"landmark\":landmark,\n                        \"Mean Radial Error\":mre_each_lm_resnet,\n                        \"X_true - X_pred\":difference_x,\n                        \"y_true - y_pred\":difference_y})\nresults.set_index(['landmark'])\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Mean Radial Error For Each LandMark","metadata":{}},{"cell_type":"code","source":"mre_df = results[[\"Mean Radial Error\"]]\nmre_df.plot(kind = \"bar\",figsize=(8,5))\n# mre_df","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# mre_each_lm_incep - mre_each_lm_resnet\n# print(\"Total MRE of Incep - Total MRE of ResNet: \",np.round(np.sum(mre_each_lm_incep)-np.sum(mre_each_lm_resnet),3))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# for i in range(len(test_labels)):\n#     print(f'mae of image {i}  = {mean_absolute_error(test_labels[i], prediction_ResNet50[i])}')\n    ","metadata":{"scrolled":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"mae_ =mean_absolute_error(test_labels, prediction_ResNet50)\n\nprint(\"MAE: \",mae_)\n\nmae_list= list(mae_)\n\nmax_mae = max(mae_list)\nmin_mae = min(mae_list)\nmid_mae = 9.303155 ##Image_Index = 58\n# median_mae = np.median(mae_list)\n\n\nmax_mae_index    = mae_list.index(max_mae)\nmin_mae_index    = mae_list.index(min_mae)\n# mid_mae_index    = mae_list.index(mid_mae)   \n# median_mae_index = mae_list.index(median_mae)\n\nprint(\"Max Error: {} , Index of Max Error: {}\".format(max_mae , max_mae_index))\nprint(\"Min Error: {} , Index of Min Error: {}\".format(min_mae , min_mae_index))\n# print(\"Median Error: {} , Index of Median Error: {}\".format(mid_mae , mid_mae_index))\n\n","metadata":{"scrolled":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nfig = plt.figure(figsize=(20, 20))\nrows = 1\ncolumns = 3\n\nfor j ,img_number,title in zip(range(1,4),[56,68,55],[\"Max MAE\",\"Mid MAE\",\"Min MAE\"]):\n    img =np.copy(test_images[img_number])\n    for i in range(0,38,2):\n            img_ = cv2.circle(img,(int(prediction_ResNet50[img_number][i]),int(prediction_ResNet50[img_number][i+1])), 2, (255,0,0),-1)\n            img_ = cv2.circle(img,(int(test_labels[img_number][i]),int(test_labels[img_number][i+1])), 2, (0,255,0),-1)\n    fig.add_subplot(rows, columns, j)\n    plt.imshow(img_)\n    plt.title(title)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"resnet50_model.save('resnet50_adabtiveLR.h5')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"resnet50_model.save('resnet50_adabtiveLR')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from IPython.display import FileLink\nFileLink(\"./resnet50_adabtiveLR.h5\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from IPython.display import FileLinks\nFileLinks(r\"./resnet50_adabtiveLR\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}